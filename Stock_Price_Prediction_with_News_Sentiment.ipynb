{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmvkPXYl+iOGW45BPtwFXX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Spidy131/Stock-Price-Prediction-with-News-Sentiment-/blob/main/Stock_Price_Prediction_with_News_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqJE24v69gSo",
        "outputId": "614f2a00-2110-4bcb-96fb-75729d46aa15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.57)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.59-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.18.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Collecting curl_cffi>=0.7 (from yfinance)\n",
            "  Downloading curl_cffi-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: protobuf<6,>=5.29.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.29.4)\n",
            "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.11/dist-packages (from curl_cffi>=0.7->yfinance) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Downloading yfinance-0.2.59-py2.py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m154.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading curl_cffi-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: curl_cffi, yfinance\n",
            "  Attempting uninstall: yfinance\n",
            "    Found existing installation: yfinance 0.2.57\n",
            "    Uninstalling yfinance-0.2.57:\n",
            "      Successfully uninstalled yfinance-0.2.57\n",
            "Successfully installed curl_cffi-0.10.0 yfinance-0.2.59\n",
            "ğŸ“¥ CSV not found. Downloading stock data...\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Data downloaded and saved to reliance_stock.csv\n",
            "         Date               Close\n",
            "0         NaN         RELIANCE.NS\n",
            "1  2015-01-01   196.6393585205078\n",
            "2  2015-01-02  196.11891174316406\n",
            "3  2015-01-05       193.970703125\n",
            "4  2015-01-06   185.1674346923828\n",
            "Date     object\n",
            "Close    object\n",
            "dtype: object\n",
            "Date      object\n",
            "Close    float64\n",
            "dtype: object\n",
            "ğŸ“° Avg News Sentiment (Last 3 Days): 0.07187921633887219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 0.0399\n",
            "Epoch 2/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - loss: 5.7035e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 52ms/step - loss: 4.8948e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 4.8158e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - loss: 5.1579e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 4.4631e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 5.1404e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 4.3726e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 3.9878e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - loss: 4.9223e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - loss: 4.1917e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 3.8555e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - loss: 4.0466e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 3.3320e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 3.3263e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - loss: 3.4735e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 3.4357e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - loss: 2.9610e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 3.4769e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m78/78\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - loss: 2.8202e-04\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "\n",
            "ğŸ“ˆ Predicted Closing Price for Tomorrow (Reliance): â‚¹1404.06\n"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install textblob scikit-learn tensorflow newsapi-python --quiet\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "\n",
        "# STEP 2: Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "from textblob import TextBlob\n",
        "from newsapi import NewsApiClient\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import os\n",
        "\n",
        "# STEP 3: Define file path and download/save data if not present\n",
        "file_path = 'reliance_stock.csv'\n",
        "start_date = '2015-01-01'\n",
        "end_date = '2025-05-08'\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"ğŸ“¥ CSV not found. Downloading stock data...\")\n",
        "    df = yf.download('RELIANCE.NS', start=start_date, end=end_date)\n",
        "    if df.empty or 'Close' not in df.columns:\n",
        "        raise ValueError(\"âŒ Stock data could not be loaded. Try again later.\")\n",
        "    df = df[['Close']].dropna().reset_index()\n",
        "    df.to_csv(file_path, index=False)\n",
        "    print(\"âœ… Data downloaded and saved to reliance_stock.csv\")\n",
        "else:\n",
        "    print(\"ğŸ“‚ CSV found. Loading saved stock data...\")\n",
        "\n",
        "# STEP 4: Load CSV\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())\n",
        "print(df.dtypes)\n",
        "# Convert 'Close' to numeric (will turn bad values to NaN)\n",
        "df['Close'] = pd.to_numeric(df['Close'], errors='coerce')\n",
        "\n",
        "# Drop rows where 'Close' couldn't be converted (i.e., NaNs)\n",
        "df = df.dropna(subset=['Close'])\n",
        "\n",
        "# Now check\n",
        "print(df.dtypes)  # 'Close' should now be float64\n",
        "# STEP 5: NewsAPI sentiment (last 3 days)\n",
        "newsapi = NewsApiClient(api_key='34e54dabb795492e904e598689209cad')  # Replace with your real API key\n",
        "\n",
        "def get_sentiment_for_date(date_str):\n",
        "    articles = newsapi.get_everything(\n",
        "        q='Reliance Industries',\n",
        "        from_param=date_str,\n",
        "        to=date_str,\n",
        "        language='en',\n",
        "        sort_by='relevancy'\n",
        "    )\n",
        "    headlines = [article['title'] for article in articles['articles']]\n",
        "    sentiments = [TextBlob(title).sentiment.polarity for title in headlines]\n",
        "    return np.mean(sentiments) if sentiments else 0.0\n",
        "\n",
        "sentiments = {}\n",
        "for i in range(3, 0, -1):\n",
        "    date = (datetime.today() - timedelta(days=i)).strftime('%Y-%m-%d')\n",
        "    sentiments[date] = get_sentiment_for_date(date)\n",
        "\n",
        "avg_sentiment = np.mean(list(sentiments.values()))\n",
        "print(\"ğŸ“° Avg News Sentiment (Last 3 Days):\", avg_sentiment)\n",
        "\n",
        "# STEP 6: Normalize close price\n",
        "scaler = MinMaxScaler()\n",
        "scaled_close = scaler.fit_transform(df[['Close']])\n",
        "\n",
        "# STEP 7: Prepare prediction input\n",
        "X_input = scaled_close[-60:]\n",
        "X_input = np.array([[val[0], avg_sentiment] for val in X_input])\n",
        "X_input = X_input.reshape((1, 60, 2))\n",
        "\n",
        "# STEP 8: Training data\n",
        "X_data, y_data = [], []\n",
        "for i in range(60, len(scaled_close)):\n",
        "    price_seq = scaled_close[i-60:i]\n",
        "    sentiment_seq = np.zeros((60, 1))  # Dummy sentiment for training\n",
        "    combined = np.hstack((price_seq, sentiment_seq))\n",
        "    X_data.append(combined)\n",
        "    y_data.append(scaled_close[i][0])\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "# STEP 9: Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, return_sequences=True, input_shape=(60, 2)))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_data, y_data, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "# STEP 10: Predict tomorrow's price\n",
        "predicted_scaled = model.predict(X_input)\n",
        "predicted_price = scaler.inverse_transform(predicted_scaled)\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Predicted Closing Price for Tomorrow (Reliance): â‚¹{predicted_price[0][0]:.2f}\")\n"
      ]
    }
  ]
}